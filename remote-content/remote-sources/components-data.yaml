# llm-d Components and Release Information
# This file contains static data for generating the Components documentation page
# Update this file when there are new releases or component changes
#
# Last synced from: https://github.com/llm-d/llm-d/releases/tag/v0.3.1
# Sync date: 2025-11-11T15:13:04.200Z

release:
  version: v0.3.1
  releaseDate: '2025-11-06'
  releaseDateFormatted: November 6, 2025
  releaseUrl: https://github.com/llm-d/llm-d/releases/tag/v0.3.1
  releaseName: v0.3.1 Release
components:
  - name: llm-d-inference-scheduler
    org: llm-d
    sidebarLabel: "Inference Scheduler"
    description: This scheduler that makes optimized routing decisions for inference requests to the llm-d inference framework.
    sidebarPosition: 1
    version: v0.3.2
  - name: llm-d-modelservice
    org: llm-d-incubation
    sidebarLabel: "Model Service"
    description: '`modelservice` is a Helm chart that simplifies LLM deployment on llm-d by declaratively managing Kubernetes resources for serving base models. It enables reproducible, scalable, and tunable model deployments through modular presets, and clean integration with llm-d ecosystem components (including vLLM, Gateway API Inference Extension, LeaderWorkerSet).'
    sidebarPosition: 2
    version: llm-d-modelservice-v0.2.10
  - name: llm-d-routing-sidecar
    org: llm-d
    sidebarLabel: "Routing Sidecar"
    description: A reverse proxy redirecting incoming requests to the prefill worker specified in the x-prefiller-host-port HTTP request header.
    sidebarPosition: 3
    version: v0.3.0
  - name: llm-d-inference-sim
    org: llm-d
    sidebarLabel: "Inference Simulator"
    description: A light weight vLLM simulator emulates responses to the HTTP REST endpoints of vLLM.
    sidebarPosition: 4
    version: v0.6.1
  - name: llm-d-infra
    org: llm-d-incubation
    sidebarLabel: "Infrastructure"
    description: A helm chart for deploying gateway and gateway related infrastructure assets for llm-d.
    sidebarPosition: 5
    version: v1.3.3
  - name: llm-d-kv-cache-manager
    org: llm-d
    sidebarLabel: "KV Cache Manager"
    description: This repository contains the llm-d-kv-cache-manager, a pluggable service designed to enable KV-Cache Aware Routing and lay the foundation for advanced, cross-node cache coordination in vLLM-based serving platforms.
    sidebarPosition: 6
    version: v0.3.0
  - name: llm-d-benchmark
    org: llm-d
    sidebarLabel: "Benchmark Tools"
    description: This repository provides an automated workflow for benchmarking LLM inference using the llm-d stack. It includes tools for deployment, experiment execution, data collection, and teardown across multiple environments and deployment styles.
    sidebarPosition: 7
    version: v0.3.0
