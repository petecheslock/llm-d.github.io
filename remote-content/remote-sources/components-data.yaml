# llm-d Components and Release Information
# This file contains static data for generating the Components documentation page
# Update this file when there are new releases or component changes
#
# Last synced from: https://github.com/llm-d/llm-d/releases/tag/v0.4.0
# Sync date: 2025-12-01T21:17:30.109Z

release:
  version: v0.4.0
  releaseDate: '2025-11-26'
  releaseDateFormatted: November 26, 2025
  releaseUrl: https://github.com/llm-d/llm-d/releases/tag/v0.4.0
  releaseName: Release v0.4.0
components:
  - name: llm-d-inference-scheduler
    org: llm-d
    sidebarLabel: Inference Scheduler
    description: This scheduler that makes optimized routing decisions for inference requests to the llm-d inference framework.
    sidebarPosition: 1
    version: v0.3.2
  - name: llm-d-modelservice
    org: llm-d-incubation
    sidebarLabel: Model Service
    description: '`modelservice` is a Helm chart that simplifies LLM deployment on llm-d by declaratively managing Kubernetes resources for serving base models. It enables reproducible, scalable, and tunable model deployments through modular presets, and clean integration with llm-d ecosystem components (including vLLM, Gateway API Inference Extension, LeaderWorkerSet).'
    sidebarPosition: 2
    version: llm-d-modelservice-v0.3.8
  - name: llm-d-inference-sim
    org: llm-d
    sidebarLabel: Inference Simulator
    description: A light weight vLLM simulator emulates responses to the HTTP REST endpoints of vLLM.
    sidebarPosition: 4
    version: v0.6.1
  - name: llm-d-infra
    org: llm-d-incubation
    sidebarLabel: Infrastructure
    description: A helm chart for deploying gateway and gateway related infrastructure assets for llm-d.
    sidebarPosition: 5
    version: v1.3.4
  - name: llm-d-kv-cache-manager
    # note: this is renamed to llm-d-kv-cache in > v0.4.0
    org: llm-d
    sidebarLabel: KV Cache Manager
    description: This repository contains the llm-d-kv-cache-manager, a pluggable service designed to enable KV-Cache Aware Routing and lay the foundation for advanced, cross-node cache coordination in vLLM-based serving platforms.
    sidebarPosition: 6
    version: v0.3.0
  - name: llm-d-benchmark
    org: llm-d
    sidebarLabel: Benchmark Tools
    description: This repository provides an automated workflow for benchmarking LLM inference using the llm-d stack. It includes tools for deployment, experiment execution, data collection, and teardown across multiple environments and deployment styles.
    sidebarPosition: 7
    version: v0.3.0
